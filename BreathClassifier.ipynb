{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "10lrmbxcZ4hwdVAH9_HNQvXPBpb5MvBjq",
      "authorship_tag": "ABX9TyNKAgIQnoJLDS6ymUrqKJ9D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAU2022-CAPSTONE-PACETIME/BreathDetector/blob/BreathClassifier/BreathClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ColabNotebooks"
      ],
      "metadata": {
        "id": "NdljSDwb21C8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b814d6a1-be49-45cb-e7d4-a53589a229e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wdnhd0jE2xbm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from imu import *\n",
        "from BreathDataset import *\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from Sound import *\n",
        "import torchaudio\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 20 # 반복 횟수"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCCfIQu10K-L",
        "outputId": "913a178f-53bc-4adf-cc8c-a74b06ebfdf4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input : mfcc(40, 44) --> (Batchsize, channel, h, w) --> (BATCH_SIZE, 1, 40, 44)\n",
        "# sound --> batchsize, 1, 22050\n",
        "class BreathClassifier(nn.Module):\n",
        "  def __init__(self, device, transformation):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "    self.transformation_mfcc = transformation\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = 4,\n",
        "            kernel_size = (3, 3),\n",
        "            stride = 1,\n",
        "            padding = 1\n",
        "        ),\n",
        "        nn.BatchNorm2d(4),\n",
        "        nn.ReLU()\n",
        "    )\n",
        " \n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels = 4,\n",
        "            out_channels = 4,\n",
        "            kernel_size = (3, 3),\n",
        "            stride = 1,\n",
        "            padding = 1\n",
        "        ),\n",
        "        nn.BatchNorm2d(4),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.fc1 = nn.Sequential(\n",
        "        nn.Linear(4*40*87, 500),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    \n",
        "    self.fc2 = nn.Sequential(\n",
        "        nn.Linear(500, 200),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.fc3 = nn.Sequential(\n",
        "        nn.Linear(200, 50),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.fc4 = nn.Sequential(\n",
        "        nn.Linear(50, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    self.dropout = nn.Dropout(0.4)\n",
        "  \n",
        "  def forward(self, input):\n",
        "    # High pass Filtering\n",
        "\n",
        "    mfcc = self.transformation_mfcc(input)\n",
        "    mfcc = mfcc.view(-1, 1, 40, 87)\n",
        "  \n",
        "    x = self.conv1(mfcc)\n",
        "    x = self.dropout(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.dropout(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    \n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.fc4(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "d1kxEe5D2275"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(train_data, batch_size):\n",
        "  data_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True, drop_last = True)\n",
        "  return data_loader\n",
        "\n",
        "def train_single_epoch(model, data_loader, loss_fn, optimizer, device):\n",
        "  for input, target in data_loader:\n",
        "    input = input.view(58, -1, 22050) # sound : batch*58x22050->58*batch*22050 imu : batch*60 -> 60*batch\n",
        "    target = target.view(58, -1) \n",
        "\n",
        "    for i in range(len(input)):\n",
        "      sound = input[i].view(-1, 22050).to(device) # sound.shape : Batchx22050\n",
        "      imu = target[i].view(-1, 1).to(device)\n",
        "      prediction = model(sound)\n",
        "      loss = loss_fn(prediction, imu)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "def train(model, data_loader, loss_fn, optimizer, device, epochs):\n",
        "  for i in range(epochs):\n",
        "    print(f\"Epoch {i + 1}\")\n",
        "    train_single_epoch(model, data_loader, loss_fn, optimizer, device)\n",
        "    print(\"------------------------------\")\n",
        "  print(\"Finished training \")\n",
        "\n",
        "\n",
        "def test(model, data_loader):\n",
        "  with torch.no_grad():\n",
        "    for input, target in data_loader:\n",
        "      input = input.view(58, -1, 22050) # sound : batch*60x40x44->60*batch*40*44 imu : batch*60 -> 60*batch\n",
        "      target = target.view(58, -1) \n",
        "        #print(\"input shape : {} target shape {}\".format(input.shape, target.shape))\n",
        "      accuracy = 0\n",
        "      total = 0\n",
        "      for i in range(len(input)):\n",
        "        sound = input[i].view(-1, 1, 22050).to(device)\n",
        "        imu = target[i].view(-1, 1).to(device)\n",
        "   \n",
        "        prediction = 1 if model(sound) >= 0.5 else 0\n",
        "        total += 1\n",
        "        accuracy += (prediction == imu).sum().item()\n",
        "    print(\"accuracy : {}\".format(100*accuracy/total))"
      ],
      "metadata": {
        "id": "9ej0kHhP24em"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  audio_list = [\"/content/drive/MyDrive/ColabNotebooks/Data/note9-budslive-sync\", \"/content/drive/MyDrive/ColabNotebooks/Data/A21s-airpodspro-sync\"]\n",
        "  device = 'cpu'\n",
        "  dataset = BreathDataset(audio_list, device)\n",
        "  print(\"Data length : {} Device : {}\".format(len(dataset), device))\n",
        "\n",
        "  train_ratio = 0.8\n",
        "  train_data_length = int(train_ratio * len(dataset))\n",
        "  test_data_length = len(dataset) - train_data_length\n",
        "\n",
        "  train_dataset, test_dataset = random_split(dataset, [train_data_length, test_data_length])\n",
        "  train_data_loader = create_data_loader(train_dataset, BATCH_SIZE)\n",
        "  test_data_loader = create_data_loader(test_dataset, 1)\n",
        "  \n",
        "  mfcc_transform = torchaudio.transforms.MFCC(\n",
        "      sample_rate=44100,\n",
        "      n_mfcc=40,\n",
        "      melkwargs={\n",
        "          \"n_fft\": 500,\n",
        "          \"hop_length\": 256,\n",
        "          \"n_mels\" : 40\n",
        "      },\n",
        "  )\n",
        "\n",
        "\n",
        "  cnn = BreathClassifier(device, mfcc_transform).to(device)\n",
        "  #print(cnn)\n",
        "\n",
        "  loss_fn = nn.BCELoss()\n",
        "  optimizer = optim.Adam(cnn.parameters(), lr = 0.001)\n",
        "\n",
        "  #train(cnn, train_data_loader, loss_fn, optimizer, device, EPOCHS)\n",
        "  #cnn.eval()\n",
        "  #torch.save(cnn.state_dict(), \"BreathClassifierVer1.2.pth\")"
      ],
      "metadata": {
        "id": "imdLPg8x26fQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e5632e-ef3a-4d9d-bc20-ba057b5c76d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data length : 85 Device : cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  test(cnn, test_data_loader)"
      ],
      "metadata": {
        "id": "2Gw0rJdFb9rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "\n",
        "model = BreathClassifier(device, mfcc_transform).to(device)\n",
        "model.load_state_dict(torch.load(\"BreathClassifierVer1.2.pth\", map_location = device))\n",
        "print(model)\n",
        "model.eval()\n",
        "for i in range(10):\n",
        "  test(model, test_data_loader)"
      ],
      "metadata": {
        "id": "Vid7SyCEZD2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf028c05-287f-4232-e984-92e2975fd1d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BreathClassifier(\n",
            "  (transformation_mfcc): MFCC(\n",
            "    (amplitude_to_DB): AmplitudeToDB()\n",
            "    (MelSpectrogram): MelSpectrogram(\n",
            "      (spectrogram): Spectrogram()\n",
            "      (mel_scale): MelScale()\n",
            "    )\n",
            "  )\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (fc1): Sequential(\n",
            "    (0): Linear(in_features=13920, out_features=500, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (fc2): Sequential(\n",
            "    (0): Linear(in_features=500, out_features=200, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (fc3): Sequential(\n",
            "    (0): Linear(in_features=200, out_features=50, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (fc4): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=1, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            "  (dropout): Dropout(p=0.4, inplace=False)\n",
            ")\n",
            "accuracy : 98.27586206896552\n",
            "accuracy : 98.27586206896552\n",
            "accuracy : 81.03448275862068\n",
            "accuracy : 96.55172413793103\n",
            "accuracy : 100.0\n",
            "accuracy : 81.03448275862068\n",
            "accuracy : 81.03448275862068\n",
            "accuracy : 93.10344827586206\n",
            "accuracy : 100.0\n",
            "accuracy : 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def sound_process(path, idx):\n",
        "  data = pd.read_csv(path)\n",
        "  data = data[\"sound\"].dropna()\n",
        "  data = np.array(data)\n",
        "  sample = data[idx*44100:idx*44100+22050]\n",
        "\n",
        "  return sample\n",
        "\n",
        "path = \"/content/drive/MyDrive/ColabNotebooks/Data/note9-airpodspro/Data_2022-11-01_18_53_03.csv\"\n",
        "sample= sound_process(path, 5)\n",
        "\n",
        "start = time.time()\n",
        "average = 0\n",
        "for i in range(20):\n",
        "  total = model(torch.Tensor(sample).to(device))\n",
        "  print(total)\n",
        "  average += total\n",
        "end = time.time()-start\n",
        "\n",
        "print(end)\n",
        "print(average/20)"
      ],
      "metadata": {
        "id": "kQ1Ib7p_eISU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model test\n",
        "\n",
        "path = \"/content/drive/MyDrive/ColabNotebooks/Data/A21s-airpodspro/Data_2022-11-04_00_55_32.csv\"\n",
        "#path = \"/content/drive/MyDrive/ColabNotebooks/Data/note9-budslive-sync/Data_2022-11-01_14_47_29.csv\"\n",
        "path = \"/content/drive/MyDrive/ColabNotebooks/Data/zflip-budspro/Data_2022-11-15_19_42_56.csv\"\n",
        "\n",
        "def model_check(model, path, device = 'cpu'):\n",
        "  data = pd.read_csv(path)\n",
        "  sound = np.array(data['sound'].dropna())\n",
        "  imu = np.array(Imu(data).get_item())\n",
        "  \n",
        "  print(\"Model Test\")\n",
        "  for s in range(58):\n",
        "    st = s * 22050\n",
        "    sound_data = sound[st:st+22050]\n",
        "\n",
        "    print(s*0.5, \" : \", model(torch.Tensor(sound_data).to(device)), end = \" \")\n",
        "    print(\"Real : \", imu[s])  \n",
        "\n",
        "model_check(model, path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkzJ29Mn7VLa",
        "outputId": "1e70304a-058e-4f4b-fed1-ec0bf8b008d7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Test\n",
            "0.0  :  tensor([[0.0004]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "0.5  :  tensor([[1.]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "1.0  :  tensor([[0.1166]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "1.5  :  tensor([[0.0002]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "2.0  :  tensor([[0.0004]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "2.5  :  tensor([[0.0403]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "3.0  :  tensor([[0.1148]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "3.5  :  tensor([[0.0593]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "4.0  :  tensor([[0.0002]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "4.5  :  tensor([[0.1756]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "5.0  :  tensor([[0.9999]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "5.5  :  tensor([[0.0554]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "6.0  :  tensor([[0.0215]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "6.5  :  tensor([[0.0047]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "7.0  :  tensor([[0.0233]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "7.5  :  tensor([[0.9876]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "8.0  :  tensor([[1.0000]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "8.5  :  tensor([[0.0291]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "9.0  :  tensor([[0.9505]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "9.5  :  tensor([[0.9966]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "10.0  :  tensor([[0.9797]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "10.5  :  tensor([[0.2192]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "11.0  :  tensor([[0.0309]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "11.5  :  tensor([[0.4785]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "12.0  :  tensor([[0.9314]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "12.5  :  tensor([[0.1231]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "13.0  :  tensor([[0.9999]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "13.5  :  tensor([[0.2755]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "14.0  :  tensor([[0.9968]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "14.5  :  tensor([[0.9120]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "15.0  :  tensor([[0.9982]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "15.5  :  tensor([[0.0002]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "16.0  :  tensor([[1.0164e-06]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "16.5  :  tensor([[0.4112]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "17.0  :  tensor([[0.8196]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "17.5  :  tensor([[0.4871]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "18.0  :  tensor([[0.9958]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "18.5  :  tensor([[0.0346]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "19.0  :  tensor([[1.1856e-06]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "19.5  :  tensor([[0.0048]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "20.0  :  tensor([[1.3980e-09]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "20.5  :  tensor([[0.3383]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "21.0  :  tensor([[0.9999]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "21.5  :  tensor([[1.]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "22.0  :  tensor([[0.9998]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "22.5  :  tensor([[0.9999]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "23.0  :  tensor([[0.9943]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "23.5  :  tensor([[0.3081]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "24.0  :  tensor([[0.9432]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "24.5  :  tensor([[0.9979]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "25.0  :  tensor([[0.9917]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "25.5  :  tensor([[1.1336e-06]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "26.0  :  tensor([[0.1321]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "26.5  :  tensor([[0.0129]], grad_fn=<SigmoidBackward0>) Real :  1\n",
            "27.0  :  tensor([[0.1639]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "27.5  :  tensor([[0.9627]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "28.0  :  tensor([[0.8517]], grad_fn=<SigmoidBackward0>) Real :  0\n",
            "28.5  :  tensor([[0.8216]], grad_fn=<SigmoidBackward0>) Real :  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch model to Pytorch mobile"
      ],
      "metadata": {
        "id": "9CuWC_82o88Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
        "scripted_model = torch.jit.script(model)\n",
        "opt_model = optimize_for_mobile(scripted_model)\n",
        "torch.jit.save(opt_model, \"/content/drive/MyDrive/ColabNotebooks/Data/Model/model1206_2.pt\")"
      ],
      "metadata": {
        "id": "T5r73UgOd-rv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GxkJxY5xthZ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}