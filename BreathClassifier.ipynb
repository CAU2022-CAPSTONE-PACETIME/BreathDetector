{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "10lrmbxcZ4hwdVAH9_HNQvXPBpb5MvBjq",
      "authorship_tag": "ABX9TyNVrD+u8AnC9voFcgl0mlH5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CAU2022-CAPSTONE-PACETIME/BreathDetector/blob/main/BreathClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ColabNotebooks"
      ],
      "metadata": {
        "id": "NdljSDwb21C8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "134b898b-68ef-4d48-fe27-e9dc90df2f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wdnhd0jE2xbm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from imu25 import *\n",
        "from BreathDataset25 import *\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from Sound import *\n",
        "import torchaudio\n",
        "import torchaudio.functional as F\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 6 # 반복 횟수"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(torchaudio.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCCfIQu10K-L",
        "outputId": "711ae1be-d20b-4f47-f2e9-149080ac4829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.0+cu116\n",
            "0.13.0+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input : mfcc(40, 44) --> (Batchsize, channel, h, w) --> (BATCH_SIZE, 1, 40, 44)\n",
        "# sound --> batchsize, 1, 11025\n",
        "class BreathClassifier(nn.Module):\n",
        "  def __init__(self, device, transformation):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "    self.transformation_mfcc = transformation\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = 4,\n",
        "            kernel_size = (3, 3),\n",
        "            stride = 1,\n",
        "            padding = 1\n",
        "        ),\n",
        "        nn.BatchNorm2d(4),\n",
        "        nn.ReLU()\n",
        "    )\n",
        " \n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels = 4,\n",
        "            out_channels = 4,\n",
        "            kernel_size = (3, 3),\n",
        "            stride = 1,\n",
        "            padding = 1\n",
        "        ),\n",
        "        nn.BatchNorm2d(4),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.fc1 = nn.Sequential(\n",
        "        nn.Linear(4*40*44, 500),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    \n",
        "    self.fc2 = nn.Sequential(\n",
        "        nn.Linear(500, 200),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.fc3 = nn.Sequential(\n",
        "        nn.Linear(200, 50),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.fc4 = nn.Sequential(\n",
        "        nn.Linear(50, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    self.dropout = nn.Dropout(0.4)\n",
        "  \n",
        "  def forward(self, input):\n",
        "    sound = F.highpass_biquad(input, 44100, 800.0)\n",
        "    mfcc = self.transformation_mfcc(sound)\n",
        "    mfcc = mfcc.view(-1, 1, 40, 44)\n",
        "\n",
        "    x = self.conv1(mfcc)\n",
        "    x = self.dropout(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.dropout(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    \n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.fc4(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "d1kxEe5D2275"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loader(train_data, batch_size):\n",
        "  data_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True, drop_last = True)\n",
        "  return data_loader\n",
        "\n",
        "def train_single_epoch(model, data_loader, loss_fn, optimizer, device):\n",
        "  for input, target in data_loader:\n",
        "    input = input.view(116, -1, 11025) # sound : batch*58x22050->58*batch*22050 imu : batch*60 -> 60*batch   // batch*116x11025\n",
        "    target = target.view(116, -1)\n",
        "\n",
        "    for i in range(len(input)):\n",
        "      sound = input[i].view(-1, 11025).to(device) # sound.shape : Batchx11025\n",
        "      imu = target[i].view(-1, 1).to(device)\n",
        "      sound = F.highpass_biquad(sound, 44100, 800.0)\n",
        "      prediction = model(sound)\n",
        "      loss = loss_fn(prediction, imu)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "def train(model, data_loader, loss_fn, optimizer, device, epochs):\n",
        "  for i in range(epochs):\n",
        "    print(f\"Epoch {i + 1}\")\n",
        "    train_single_epoch(model, data_loader, loss_fn, optimizer, device)\n",
        "    print(\"------------------------------\")\n",
        "  print(\"Finished training \")\n",
        "\n",
        "\n",
        "def test(model, data_loader):\n",
        "  with torch.no_grad():\n",
        "    for input, target in data_loader:\n",
        "      input = input.view(116, -1, 11025) # sound : batch*60x40x44->60*batch*40*44 imu : batch*60 -> 60*batch\n",
        "      target = target.view(116, -1) \n",
        "      #print(\"input shape : {} target shape {}\".format(input.shape, target.shape))\n",
        "      accuracy = 0\n",
        "      total = 0\n",
        "      for i in range(len(input)):\n",
        "        sound = input[i].view(-1, 1, 11025).to(device)\n",
        "        imu = target[i].view(-1, 1).to(device)\n",
        "        #sound = F.highpass_biquad(sound, 44100, 800.0)\n",
        "\n",
        "        prediction = 1 if model(sound) >= 0.5 else 0\n",
        "        total += 1\n",
        "        accuracy += (prediction == imu).sum().item()\n",
        "    print(\"accuracy : {}\".format(100*accuracy/total))"
      ],
      "metadata": {
        "id": "9ej0kHhP24em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  audio_list = [\"/content/drive/MyDrive/ColabNotebooks/Data/note9-budslive-sync\", \"/content/drive/MyDrive/ColabNotebooks/Data/A21s-airpodspro-sync\"]\n",
        "  aug_audio_list = [\"/content/drive/MyDrive/ColabNotebooks/Data/Augment_data\"]\n",
        "\n",
        "  device = 'cpu'\n",
        "  dataset = BreathDataset(audio_list)\n",
        "  aug_dataset = BreathDataset(aug_audio_list)\n",
        "  print(\"Data length : {} Device : {}\".format(len(dataset) + len(aug_dataset), device))\n",
        "\n",
        "  train_ratio = 0.9\n",
        "  train_data_length = int(train_ratio * len(dataset))\n",
        "  test_data_length = len(dataset) - train_data_length\n",
        "  \n",
        "  train_dataset, test_dataset = random_split(dataset, [train_data_length, test_data_length])\n",
        "  train_data_loader = create_data_loader(train_dataset, BATCH_SIZE)\n",
        "  train_aug_data_loader = create_data_loader(aug_dataset, BATCH_SIZE)\n",
        "  test_data_loader = create_data_loader(test_dataset, 1)\n",
        "  \n",
        "  mfcc_transform = torchaudio.transforms.MFCC(\n",
        "      sample_rate=44100,\n",
        "      n_mfcc=40,\n",
        "      melkwargs={\n",
        "          \"n_fft\": 500,\n",
        "          \"hop_length\": 256,\n",
        "          \"n_mels\" : 40\n",
        "      },\n",
        "  )\n",
        "\n",
        "\n",
        "  cnn = BreathClassifier(device, mfcc_transform).to(device)\n",
        "\n",
        "  loss_fn = nn.BCELoss()\n",
        "  optimizer = optim.Adam(cnn.parameters(), lr = 0.001)\n",
        "\n",
        "  train(cnn, train_data_loader, loss_fn, optimizer, device, EPOCHS)\n",
        "  train(cnn, train_aug_data_loader, loss_fn, optimizer, device, EPOCHS)\n",
        "  cnn.eval()\n",
        "  torch.save(cnn.state_dict(), \"BreathClassifierVer2.2.pth\")"
      ],
      "metadata": {
        "id": "imdLPg8x26fQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e673a591-e0da-4e9c-af4b-525757de04d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data length : 220 Device : cpu\n",
            "Epoch 1\n",
            "------------------------------\n",
            "Epoch 2\n",
            "------------------------------\n",
            "Epoch 3\n",
            "------------------------------\n",
            "Epoch 4\n",
            "------------------------------\n",
            "Epoch 5\n",
            "------------------------------\n",
            "Epoch 6\n",
            "------------------------------\n",
            "Finished training \n",
            "Epoch 1\n",
            "------------------------------\n",
            "Epoch 2\n",
            "------------------------------\n",
            "Epoch 3\n",
            "------------------------------\n",
            "Epoch 4\n",
            "------------------------------\n",
            "Epoch 5\n",
            "------------------------------\n",
            "Epoch 6\n",
            "------------------------------\n",
            "Finished training \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  test(cnn, test_data_loader)"
      ],
      "metadata": {
        "id": "2Gw0rJdFb9rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "\n",
        "model = BreathClassifier(device, mfcc_transform).to(device)\n",
        "model.load_state_dict(torch.load(\"BreathClassifierVer2.1.pth\", map_location = device))\n",
        "model.eval()\n",
        "# for i in range(10):\n",
        "#   test(model, test_data_loader)"
      ],
      "metadata": {
        "id": "Vid7SyCEZD2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def sound_process(path, idx, device = 'cpu'):\n",
        "  data = pd.read_csv(path)\n",
        "  data = data[\"sound\"].dropna()\n",
        "  data = np.array(data)\n",
        "  print(\"{}s ~ {}s\".format(idx, idx + 0.25))\n",
        "  sample = data[int(idx*44100):int(idx*44100)+11025]\n",
        "  sample = torch.FloatTensor(sample).to(device)\n",
        "  sound = F.highpass_biquad(sample, 44100, 800.0)\n",
        "  return sound\n",
        "\n",
        "path = \"/content/drive/MyDrive/ColabNotebooks/Data/A21s-airpodspro/Data_2022-11-01_18_53_03.csv\"\n",
        "#path = \"/content/drive/MyDrive/ColabNotebooks/Data/noise/Data_2022-12-06_22_05_45.csv\"\n",
        "path = \"/content/drive/MyDrive/ColabNotebooks/Data/zflip-budspro/Data_2022-11-15_19_49_18.csv\"\n",
        "path = \"/content/drive/MyDrive/ColabNotebooks/Data/noise/Data_2022-12-06_22_51_02.csv\"\n",
        "sample= sound_process(path, 3.8)\n",
        "\n",
        "start = time.time()\n",
        "average = 0\n",
        "total = model(sample)\n",
        "print(total)"
      ],
      "metadata": {
        "id": "kQ1Ib7p_eISU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf7a349-fbc0-4f26-ff9a-8eb29b5d3a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.8s ~ 4.05s\n",
            "tensor([[0.0161]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model test\n",
        "\n",
        "path = \"/content/drive/MyDrive/ColabNotebooks/Data/A21s-airpodspro/Data_2022-11-04_00_55_32.csv\"\n",
        "\n",
        "\n",
        "def model_check(model, path, device = 'cpu'):\n",
        "  data = pd.read_csv(path)\n",
        "  sound = np.array(data['sound'].dropna())\n",
        "  imu = np.array(Imu(data).get_item())\n",
        "  \n",
        "  print(\"Model Test\")\n",
        "  for s in range(116):\n",
        "    st = s * 11025\n",
        "    sound_data = sound[st:st+11025]\n",
        "    sound_data = torch.FloatTensor(sound_data).to(device)\n",
        "    sound_data = F.highpass_biquad(sound_data, 44100, 800.0)\n",
        "    val = model(sound_data).detach().numpy()[0][0]\n",
        "    res = \"Exhale\" if val < 0.5 else \"Inhale\"\n",
        "    print(\"{:.2f}s value : {:.5f} --> {}\".format(s*0.25, val, res))\n",
        "\n",
        "model_check(model, path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkzJ29Mn7VLa",
        "outputId": "03d62b75-fdc2-4125-cc47-5dfb6b0c564f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Test\n",
            "0.00s value : 0.00004 --> Exhale\n",
            "0.25s value : 0.00000 --> Exhale\n",
            "0.50s value : 0.89548 --> Inhale\n",
            "0.75s value : 0.41531 --> Exhale\n",
            "1.00s value : 0.10232 --> Exhale\n",
            "1.25s value : 0.88948 --> Inhale\n",
            "1.50s value : 0.17355 --> Exhale\n",
            "1.75s value : 0.00000 --> Exhale\n",
            "2.00s value : 0.12013 --> Exhale\n",
            "2.25s value : 0.93206 --> Inhale\n",
            "2.50s value : 0.15119 --> Exhale\n",
            "2.75s value : 0.68130 --> Inhale\n",
            "3.00s value : 0.06587 --> Exhale\n",
            "3.25s value : 0.00000 --> Exhale\n",
            "3.50s value : 0.99087 --> Inhale\n",
            "3.75s value : 0.99955 --> Inhale\n",
            "4.00s value : 0.80234 --> Inhale\n",
            "4.25s value : 0.87373 --> Inhale\n",
            "4.50s value : 0.11659 --> Exhale\n",
            "4.75s value : 0.99011 --> Inhale\n",
            "5.00s value : 0.99978 --> Inhale\n",
            "5.25s value : 0.01791 --> Exhale\n",
            "5.50s value : 0.63835 --> Inhale\n",
            "5.75s value : 0.06282 --> Exhale\n",
            "6.00s value : 0.01376 --> Exhale\n",
            "6.25s value : 0.97994 --> Inhale\n",
            "6.50s value : 0.99932 --> Inhale\n",
            "6.75s value : 0.37044 --> Exhale\n",
            "7.00s value : 0.04052 --> Exhale\n",
            "7.25s value : 0.07251 --> Exhale\n",
            "7.50s value : 0.11041 --> Exhale\n",
            "7.75s value : 0.01622 --> Exhale\n",
            "8.00s value : 0.99975 --> Inhale\n",
            "8.25s value : 0.99311 --> Inhale\n",
            "8.50s value : 0.01200 --> Exhale\n",
            "8.75s value : 0.00498 --> Exhale\n",
            "9.00s value : 0.27405 --> Exhale\n",
            "9.25s value : 0.01701 --> Exhale\n",
            "9.50s value : 0.99960 --> Inhale\n",
            "9.75s value : 0.99988 --> Inhale\n",
            "10.00s value : 0.93529 --> Inhale\n",
            "10.25s value : 0.76770 --> Inhale\n",
            "10.50s value : 0.56755 --> Inhale\n",
            "10.75s value : 0.01011 --> Exhale\n",
            "11.00s value : 0.99999 --> Inhale\n",
            "11.25s value : 0.99990 --> Inhale\n",
            "11.50s value : 0.03939 --> Exhale\n",
            "11.75s value : 0.12297 --> Exhale\n",
            "12.00s value : 0.00443 --> Exhale\n",
            "12.25s value : 0.01756 --> Exhale\n",
            "12.50s value : 0.06284 --> Exhale\n",
            "12.75s value : 1.00000 --> Inhale\n",
            "13.00s value : 0.99969 --> Inhale\n",
            "13.25s value : 0.30543 --> Exhale\n",
            "13.50s value : 0.95431 --> Inhale\n",
            "13.75s value : 0.04410 --> Exhale\n",
            "14.00s value : 0.99965 --> Inhale\n",
            "14.25s value : 0.99849 --> Inhale\n",
            "14.50s value : 0.96778 --> Inhale\n",
            "14.75s value : 0.71520 --> Inhale\n",
            "15.00s value : 0.39735 --> Exhale\n",
            "15.25s value : 0.01785 --> Exhale\n",
            "15.50s value : 0.75870 --> Inhale\n",
            "15.75s value : 0.96443 --> Inhale\n",
            "16.00s value : 0.11024 --> Exhale\n",
            "16.25s value : 0.02554 --> Exhale\n",
            "16.50s value : 0.67406 --> Inhale\n",
            "16.75s value : 0.59287 --> Inhale\n",
            "17.00s value : 0.08547 --> Exhale\n",
            "17.25s value : 0.99990 --> Inhale\n",
            "17.50s value : 0.24761 --> Exhale\n",
            "17.75s value : 0.12298 --> Exhale\n",
            "18.00s value : 0.55919 --> Inhale\n",
            "18.25s value : 0.01564 --> Exhale\n",
            "18.50s value : 0.00300 --> Exhale\n",
            "18.75s value : 0.99992 --> Inhale\n",
            "19.00s value : 0.97138 --> Inhale\n",
            "19.25s value : 0.00475 --> Exhale\n",
            "19.50s value : 0.67370 --> Inhale\n",
            "19.75s value : 0.28428 --> Exhale\n",
            "20.00s value : 0.13805 --> Exhale\n",
            "20.25s value : 0.88640 --> Inhale\n",
            "20.50s value : 0.93686 --> Inhale\n",
            "20.75s value : 0.21330 --> Exhale\n",
            "21.00s value : 0.97095 --> Inhale\n",
            "21.25s value : 0.83555 --> Inhale\n",
            "21.50s value : 0.00009 --> Exhale\n",
            "21.75s value : 0.07277 --> Exhale\n",
            "22.00s value : 0.83118 --> Inhale\n",
            "22.25s value : 0.98513 --> Inhale\n",
            "22.50s value : 0.02229 --> Exhale\n",
            "22.75s value : 0.56218 --> Inhale\n",
            "23.00s value : 0.11161 --> Exhale\n",
            "23.25s value : 0.00004 --> Exhale\n",
            "23.50s value : 0.93417 --> Inhale\n",
            "23.75s value : 0.20436 --> Exhale\n",
            "24.00s value : 0.00007 --> Exhale\n",
            "24.25s value : 0.42910 --> Exhale\n",
            "24.50s value : 0.97189 --> Inhale\n",
            "24.75s value : 0.05932 --> Exhale\n",
            "25.00s value : 0.99994 --> Inhale\n",
            "25.25s value : 0.99904 --> Inhale\n",
            "25.50s value : 0.18231 --> Exhale\n",
            "25.75s value : 0.33432 --> Exhale\n",
            "26.00s value : 0.11282 --> Exhale\n",
            "26.25s value : 0.56631 --> Inhale\n",
            "26.50s value : 0.01793 --> Exhale\n",
            "26.75s value : 0.99592 --> Inhale\n",
            "27.00s value : 0.94209 --> Inhale\n",
            "27.25s value : 0.66868 --> Inhale\n",
            "27.50s value : 0.00559 --> Exhale\n",
            "27.75s value : 0.19662 --> Exhale\n",
            "28.00s value : 0.04677 --> Exhale\n",
            "28.25s value : 0.99974 --> Inhale\n",
            "28.50s value : 0.38926 --> Exhale\n",
            "28.75s value : 0.03237 --> Exhale\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch model to Pytorch mobile"
      ],
      "metadata": {
        "id": "9CuWC_82o88Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "\n",
        "model = BreathClassifier(device, mfcc_transform).to(device)\n",
        "model.load_state_dict(torch.load(\"BreathClassifierVer1.9.pth\", map_location = device))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "cfMIlqudj7mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"BreathClassifierVer1.9\"\n",
        "pt_path = \"/content/drive/MyDrive/ColabNotebooks/Data/Model/\" + name + \".pt\"\n",
        "ptl_path = \"/content/drive/MyDrive/ColabNotebooks/Data/Model/\" + name + \".ptl\"\n",
        "yaml_path = \"/content/drive/MyDrive/ColabNotebooks/Data/Model/\" + name + \".yaml\""
      ],
      "metadata": {
        "id": "KQimRrpGFaRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
        "scripted_model = torch.jit.script(model)\n",
        "opt_model = optimize_for_mobile(scripted_model)\n",
        "torch.jit.save(opt_model, pt_path)\n",
        "opt_model._save_for_lite_interpreter(ptl_path)"
      ],
      "metadata": {
        "id": "T5r73UgOd-rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, yaml\n",
        "\n",
        "model = torch.jit.load(pt_path)\n",
        "ops = torch.jit.export_opnames(model)\n",
        "with open(yaml_path, 'w') as output:\n",
        "    yaml.dump(ops, output)"
      ],
      "metadata": {
        "id": "GxkJxY5xthZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y9bkGVNnQXoe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}